{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ontology_objects.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "raknSd4GGhSH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install deeppavlov"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nGi0fpz6GnZ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python -m deeppavlov install ner_conll2003"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6BDYNYq6Gncd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"dataset_reader\": {\n",
        "        \"class_name\": \"conll2003_reader\",\n",
        "        \"data_path\": \"./onthology_objects_data_new/dataset_1/\",\n",
        "        \"dataset_name\": \"conll2003\",\n",
        "        \"provide_pos\": False\n",
        "    },\n",
        "    \"dataset_iterator\": {\n",
        "        \"class_name\": \"data_learning_iterator\",\n",
        "        \"seed\": 42\n",
        "    },\n",
        "    \"chainer\": {\n",
        "    \"in\": [\"x\"],\n",
        "    \"in_y\": [\"y\"],\n",
        "    \"pipe\": [\n",
        "      {\n",
        "        \"in\": [\"x\"],\n",
        "        \"class_name\": \"lazy_tokenizer\",\n",
        "        \"out\": [\"x_tokens\"]\n",
        "      },\n",
        "      {\n",
        "        \"in\": [\"x_tokens\"],\n",
        "        \"class_name\": \"str_lower\",\n",
        "        \"out\": [\"x_lower\"]\n",
        "      },\n",
        "      {\n",
        "        \"in\": [\"x_lower\"],\n",
        "        \"class_name\": \"sanitizer\",\n",
        "        \"nums\": True,\n",
        "        \"out\": [\"x_san\"]\n",
        "      },\n",
        "      {\n",
        "        \"in\": [\"x_san\"],\n",
        "        \"id\": \"word_vocab\",\n",
        "        \"class_name\": \"simple_vocab\",\n",
        "        \"pad_with_zeros\": True,\n",
        "        \"special_tokens\": [\"<UNK>\"],\n",
        "        \"fit_on\": [\"x_san\"],\n",
        "        \"save_path\": \"{MODELS_PATH}/onthology_objects/word.dict\",\n",
        "        \"load_path\": \"{MODELS_PATH}/onthology_objects/word.dict\",\n",
        "        \"out\": [\"x_tok_ind\"]\n",
        "      },\n",
        "      {\n",
        "        \"in\": [\"y\"],\n",
        "        \"id\": \"tag_vocab\",\n",
        "        \"class_name\": \"simple_vocab\",\n",
        "        \"pad_with_zeros\": True,\n",
        "        \"fit_on\": [\"y\"],\n",
        "        \"save_path\": \"{MODELS_PATH}/onthology_objects/tag.dict\",\n",
        "        \"load_path\": \"{MODELS_PATH}/onthology_objects/tag.dict\",\n",
        "        \"out\": [\"y_ind\"]\n",
        "      },\n",
        "      {\n",
        "        \"in\": [\"x_tokens\"],\n",
        "        \"class_name\": \"char_splitter\",\n",
        "        \"out\": [\"x_char\"]\n",
        "      },\n",
        "      {\n",
        "        \"in\": [\"x_char\"],\n",
        "        \"id\": \"char_vocab\",\n",
        "        \"class_name\": \"simple_vocab\",\n",
        "        \"pad_with_zeros\": True,\n",
        "        \"fit_on\": [\"x_char\"],\n",
        "        \"save_path\": \"{MODELS_PATH}/onthology_objects/char.dict\",\n",
        "        \"load_path\": \"{MODELS_PATH}/onthology_objects/char.dict\",\n",
        "        \"out\": [\"x_char_ind\"]\n",
        "      },\n",
        "      {\n",
        "        \"in\": [\"x_tokens\"],\n",
        "        \"class_name\": \"mask\",\n",
        "        \"out\": [\"mask\"]\n",
        "      },\n",
        "      {\n",
        "        \"in\": [\"x_san\"],\n",
        "        \"id\": \"glove_emb\",\n",
        "        \"class_name\": \"glove\",\n",
        "        \"pad_zero\": True,\n",
        "        \"load_path\": \"{DOWNLOADS_PATH}/embeddings/glove.6B.100d.txt\",\n",
        "        \"out\": [\"x_emb\"]\n",
        "      },\n",
        "      {\n",
        "        \"id\": \"embeddings\",\n",
        "        \"class_name\": \"emb_mat_assembler\",\n",
        "        \"embedder\": \"#glove_emb\",\n",
        "        \"vocab\": \"#word_vocab\"\n",
        "      },\n",
        "      {\n",
        "        \"id\": \"embeddings_char\",\n",
        "        \"class_name\": \"emb_mat_assembler\",\n",
        "        \"character_level\": True,\n",
        "        \"emb_dim\": 32,\n",
        "        \"embedder\": \"#glove_emb\",\n",
        "        \"vocab\": \"#char_vocab\"\n",
        "      },\n",
        "      {\n",
        "        \"id\": \"capitalization\",\n",
        "        \"class_name\": \"capitalization_featurizer\",\n",
        "        \"in\": [\"x_tokens\"],\n",
        "        \"out\": [\"cap\"]\n",
        "      },\n",
        "      {\n",
        "        \"in\": [\"x_emb\", \"mask\", \"x_char_ind\", \"cap\"],\n",
        "        \"in_y\": [\"y_ind\"],\n",
        "        \"out\": [\"y_predicted\"],\n",
        "        \"class_name\": \"ner\",\n",
        "        \"main\": True,\n",
        "        \"token_emb_dim\": \"#glove_emb.dim\",\n",
        "        \"n_hidden_list\": [128],\n",
        "        \"net_type\": \"rnn\",\n",
        "        \"cell_type\": \"lstm\",\n",
        "        \"use_cudnn_rnn\": True,\n",
        "        \"n_tags\": \"#tag_vocab.len\",\n",
        "        \"capitalization_dim\": \"#capitalization.dim\",\n",
        "        \"char_emb_dim\": \"#embeddings_char.dim\",\n",
        "        \"save_path\": \"{MODELS_PATH}/onthology_objects/model_no_pos\",\n",
        "        \"load_path\": \"{MODELS_PATH}/onthology_objects/model_no_pos\",\n",
        "        \"char_emb_mat\": \"#embeddings_char.emb_mat\",\n",
        "        \"two_dense_on_top\": True,\n",
        "        \"use_crf\": True,\n",
        "        \"use_batch_norm\": True,\n",
        "        \"embeddings_dropout\": True,\n",
        "        \"top_dropout\": True,\n",
        "        \"intra_layer_dropout\": True,\n",
        "        \"l2_reg\": 0,\n",
        "        \"learning_rate\": 1e-2,\n",
        "        \"dropout_keep_prob\": 0.5\n",
        "      },\n",
        "      {\n",
        "        \"ref\": \"tag_vocab\",\n",
        "        \"in\": [\"y_predicted\"],\n",
        "        \"out\": [\"tags\"]\n",
        "      }\n",
        "    ],\n",
        "    \"out\": [\"x_tokens\", \"tags\"]\n",
        "  },\n",
        "    \"train\": {\n",
        "        \"epochs\": 100,\n",
        "        \"batch_size\": 64,\n",
        "        \"metrics\": [\n",
        "            {\n",
        "                \"name\": \"ner_f1\",\n",
        "                \"inputs\": [\n",
        "                    \"y\",\n",
        "                    \"tags\"\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"validation_patience\": 7,\n",
        "        \"val_every_n_epochs\": 1,\n",
        "        \"log_every_n_epochs\": -1,\n",
        "        \"show_examples\": False,\n",
        "        \"validate_best\": True,\n",
        "        \"test_best\": True\n",
        "    },\n",
        "    \"metadata\": {\n",
        "        \"variables\": {\n",
        "            \"ROOT_PATH\": \".\",\n",
        "            \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\n",
        "            \"MODELS_PATH\": \"{ROOT_PATH}/models\"\n",
        "        },\n",
        "        \"requirements\": [\n",
        "            \"{DEEPPAVLOV_PATH}/requirements/gensim.txt\",\n",
        "            \"{DEEPPAVLOV_PATH}/requirements/tf.txt\"\n",
        "        ],\n",
        "        \"labels\": {\n",
        "            \"telegram_utils\": \"NERCoNLL2003Model\",\n",
        "            \"server_utils\": \"NER\"\n",
        "        },\n",
        "        \"download\": [\n",
        "            {\n",
        "                \"url\": \"http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt\",\n",
        "                \"subdir\": \"{DOWNLOADS_PATH}/embeddings\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v76D1jCPMS-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"config.json\", \"w\") as fout:\n",
        "  json.dump(config, fout, ensure_ascii=False, indent=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "euX5zL5MGvMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "0a447211-2935-4936-ab8d-118abad631bd"
      },
      "cell_type": "code",
      "source": [
        "!python -m deeppavlov download config.json"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:18:56.491 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 208: Starting new HTTP connection (1): files.deeppavlov.ai\n",
            "2018-12-10 08:18:56.886 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 396: http://files.deeppavlov.ai:80 \"GET /embeddings/glove.6B.100d.txt.md5 HTTP/1.1\" 200 52\n",
            "2018-12-10 08:18:56.890 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 208: Starting new HTTP connection (1): files.deeppavlov.ai\n",
            "2018-12-10 08:18:57.254 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 396: http://files.deeppavlov.ai:80 \"GET /embeddings/glove.6B.100d.txt HTTP/1.1\" 200 None\n",
            "2018-12-10 08:18:57.255 INFO in 'deeppavlov.core.data.utils'['utils'] at line 63: Downloading from http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt to /content/downloads/embeddings/glove.6B.100d.txt\n",
            "347MB [00:30, 11.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sa_UM03gGne7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from deeppavlov import build_model, train_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kpbr1l_2GnhH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "fa21f034-e550-4b3f-cd1c-c3caca72cb46"
      },
      "cell_type": "code",
      "source": [
        "!wget http://files.deeppavlov.ai/datasets/onthology_objects_data_new.zip"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-10 08:39:10--  http://files.deeppavlov.ai/datasets/onthology_objects_data_new.zip\n",
            "Resolving files.deeppavlov.ai (files.deeppavlov.ai)... 93.175.29.74\n",
            "Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Cookie coming from files.deeppavlov.ai attempted to set domain to lnsigo.mipt.ru\n",
            "Length: 346661 (339K) [application/zip]\n",
            "Saving to: ‘onthology_objects_data_new.zip’\n",
            "\n",
            "onthology_objects_d 100%[===================>] 338.54K   469KB/s    in 0.7s    \n",
            "\n",
            "2018-12-10 08:39:11 (469 KB/s) - ‘onthology_objects_data_new.zip’ saved [346661/346661]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FSD0Q5kMGnjw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "9ef79b49-94fa-4c45-e9a7-a75a675b02e5"
      },
      "cell_type": "code",
      "source": [
        "! unzip onthology_objects_data_new.zip"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  onthology_objects_data_new.zip\n",
            "   creating: onthology_objects_data_new/\n",
            "   creating: onthology_objects_data_new/dataset_1/\n",
            "  inflating: onthology_objects_data_new/dataset_1/test.txt  \n",
            "  inflating: onthology_objects_data_new/dataset_1/train.txt  \n",
            "  inflating: onthology_objects_data_new/dataset_1/valid.txt  \n",
            "   creating: onthology_objects_data_new/dataset_2/\n",
            "  inflating: onthology_objects_data_new/dataset_2/test.txt  \n",
            "  inflating: onthology_objects_data_new/dataset_2/train.txt  \n",
            "  inflating: onthology_objects_data_new/dataset_2/valid.txt  \n",
            "   creating: onthology_objects_data_new/dataset_3/\n",
            "  inflating: onthology_objects_data_new/dataset_3/test.txt  \n",
            "  inflating: onthology_objects_data_new/dataset_3/train.txt  \n",
            "  inflating: onthology_objects_data_new/dataset_3/valid.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nddNgeJ4GnmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3027
        },
        "outputId": "b6be1b96-9348-4489-bed4-6dbd65dded4d"
      },
      "cell_type": "code",
      "source": [
        "model = train_model(config)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:39:18.459 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/word.dict]\n",
            "2018-12-10 08:39:18.625 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 89: [saving vocabulary to /content/models/onthology_objects/word.dict]\n",
            "2018-12-10 08:39:18.637 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/tag.dict]\n",
            "2018-12-10 08:39:19.105 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 89: [saving vocabulary to /content/models/onthology_objects/tag.dict]\n",
            "2018-12-10 08:39:19.108 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/char.dict]\n",
            "2018-12-10 08:39:19.631 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 89: [saving vocabulary to /content/models/onthology_objects/char.dict]\n",
            "2018-12-10 08:39:19.633 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/content/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2018-12-10 08:39:19.635 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 204: loading projection weights from /content/downloads/embeddings/glove.6B.100d.txt\n",
            "2018-12-10 08:39:19.636 DEBUG in 'smart_open.smart_open_lib'['smart_open_lib'] at line 176: {'kw': {}, 'mode': 'rb', 'uri': '/content/downloads/embeddings/glove.6B.100d.txt'}\n",
            "2018-12-10 08:39:53.19 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 266: loaded (400000, 100) matrix from /content/downloads/embeddings/glove.6B.100d.txt\n",
            "2018-12-10 08:39:54.615 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2018-12-10 08:39:54.731 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "2018-12-10 08:39:56.777 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 43: [loading model from /content/models/onthology_objects/model_no_pos]\n",
            "2018-12-10 08:39:56.807 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from /content/models/onthology_objects/model_no_pos\n",
            "2018-12-10 08:39:58.780 INFO in 'deeppavlov.core.commands.train'['train'] at line 363: New best ner_f1 of 8.5014\n",
            "2018-12-10 08:39:58.782 INFO in 'deeppavlov.core.commands.train'['train'] at line 365: Saving model\n",
            "2018-12-10 08:39:58.788 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 8.5014}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:40:48.676 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 18.2116\n",
            "2018-12-10 08:40:48.678 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:40:48.679 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 18.2116}, \"time_spent\": \"0:00:52\", \"epochs_done\": 1, \"batches_seen\": 28, \"train_examples_seen\": 1771, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:41:37.387 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 52.1502\n",
            "2018-12-10 08:41:37.388 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:41:37.390 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 52.1502}, \"time_spent\": \"0:01:41\", \"epochs_done\": 2, \"batches_seen\": 56, \"train_examples_seen\": 3542, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:42:28.875 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 57.8669\n",
            "2018-12-10 08:42:28.876 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:42:28.877 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 57.8669}, \"time_spent\": \"0:02:32\", \"epochs_done\": 3, \"batches_seen\": 84, \"train_examples_seen\": 5313, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:43:19.922 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 61.5545\n",
            "2018-12-10 08:43:19.923 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:43:19.925 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 61.5545}, \"time_spent\": \"0:03:24\", \"epochs_done\": 4, \"batches_seen\": 112, \"train_examples_seen\": 7084, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:44:13.6 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 64.5459\n",
            "2018-12-10 08:44:13.7 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:44:13.14 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 64.5459}, \"time_spent\": \"0:04:17\", \"epochs_done\": 5, \"batches_seen\": 140, \"train_examples_seen\": 8855, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:45:06.222 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 67.9726\n",
            "2018-12-10 08:45:06.224 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:45:06.225 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 67.9726}, \"time_spent\": \"0:05:10\", \"epochs_done\": 6, \"batches_seen\": 168, \"train_examples_seen\": 10626, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:45:59.183 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 69.6\n",
            "2018-12-10 08:45:59.184 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:45:59.196 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 69.6}, \"time_spent\": \"0:06:03\", \"epochs_done\": 7, \"batches_seen\": 196, \"train_examples_seen\": 12397, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:46:53.329 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 69.6127\n",
            "2018-12-10 08:46:53.330 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:46:53.337 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 69.6127}, \"time_spent\": \"0:06:57\", \"epochs_done\": 8, \"batches_seen\": 224, \"train_examples_seen\": 14168, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:47:47.677 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 70.5998\n",
            "2018-12-10 08:47:47.678 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:47:47.680 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 70.5998}, \"time_spent\": \"0:07:51\", \"epochs_done\": 9, \"batches_seen\": 252, \"train_examples_seen\": 15939, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:48:40.867 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 70.5998\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 70.5071}, \"time_spent\": \"0:08:44\", \"epochs_done\": 10, \"batches_seen\": 280, \"train_examples_seen\": 17710, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:49:34.492 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 70.5998\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 69.8507}, \"time_spent\": \"0:09:38\", \"epochs_done\": 11, \"batches_seen\": 308, \"train_examples_seen\": 19481, \"impatience\": 2, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:50:29.54 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 70.5998\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 70.5882}, \"time_spent\": \"0:10:33\", \"epochs_done\": 12, \"batches_seen\": 336, \"train_examples_seen\": 21252, \"impatience\": 3, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:51:24.436 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 71.3078\n",
            "2018-12-10 08:51:24.437 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:51:24.439 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 71.3078}, \"time_spent\": \"0:11:28\", \"epochs_done\": 13, \"batches_seen\": 364, \"train_examples_seen\": 23023, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:52:19.830 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 71.3078\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 69.3211}, \"time_spent\": \"0:12:23\", \"epochs_done\": 14, \"batches_seen\": 392, \"train_examples_seen\": 24794, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:53:13.122 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 72.1295\n",
            "2018-12-10 08:53:13.123 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:53:13.124 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 72.1295}, \"time_spent\": \"0:13:17\", \"epochs_done\": 15, \"batches_seen\": 420, \"train_examples_seen\": 26565, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:54:08.311 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 72.1295\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 71.6085}, \"time_spent\": \"0:14:12\", \"epochs_done\": 16, \"batches_seen\": 448, \"train_examples_seen\": 28336, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:55:03.1 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 74.0119\n",
            "2018-12-10 08:55:03.2 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 08:55:03.8 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.0119}, \"time_spent\": \"0:15:07\", \"epochs_done\": 17, \"batches_seen\": 476, \"train_examples_seen\": 30107, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:55:57.429 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.0119\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 73.2366}, \"time_spent\": \"0:16:01\", \"epochs_done\": 18, \"batches_seen\": 504, \"train_examples_seen\": 31878, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:56:50.343 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.0119\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 71.4286}, \"time_spent\": \"0:16:54\", \"epochs_done\": 19, \"batches_seen\": 532, \"train_examples_seen\": 33649, \"impatience\": 2, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:57:43.623 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.0119\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 72.9783}, \"time_spent\": \"0:17:47\", \"epochs_done\": 20, \"batches_seen\": 560, \"train_examples_seen\": 35420, \"impatience\": 3, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:58:36.842 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.0119\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 72.7908}, \"time_spent\": \"0:18:40\", \"epochs_done\": 21, \"batches_seen\": 588, \"train_examples_seen\": 37191, \"impatience\": 4, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 08:59:30.108 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.0119\n",
            "2018-12-10 08:59:30.110 INFO in 'deeppavlov.models.ner.network'['network'] at line 343: Dropping learning rate from 1.0e-02 to 1.0e-03\n",
            "2018-12-10 08:59:30.119 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 43: [loading model from /content/models/onthology_objects/model_no_pos]\n",
            "2018-12-10 08:59:30.147 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from /content/models/onthology_objects/model_no_pos\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 73.5076}, \"time_spent\": \"0:19:34\", \"epochs_done\": 22, \"batches_seen\": 616, \"train_examples_seen\": 38962, \"impatience\": 5, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:00:23.285 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.0119\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 73.9941}, \"time_spent\": \"0:20:27\", \"epochs_done\": 23, \"batches_seen\": 644, \"train_examples_seen\": 40733, \"impatience\": 6, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:01:17.293 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 74.6298\n",
            "2018-12-10 09:01:17.294 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 09:01:17.298 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.6298}, \"time_spent\": \"0:21:21\", \"epochs_done\": 24, \"batches_seen\": 672, \"train_examples_seen\": 42504, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:02:11.252 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.6298\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 73.6426}, \"time_spent\": \"0:22:15\", \"epochs_done\": 25, \"batches_seen\": 700, \"train_examples_seen\": 44275, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:03:05.554 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.6298\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 73.5236}, \"time_spent\": \"0:23:09\", \"epochs_done\": 26, \"batches_seen\": 728, \"train_examples_seen\": 46046, \"impatience\": 2, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:04:00.284 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.6298\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.5059}, \"time_spent\": \"0:24:04\", \"epochs_done\": 27, \"batches_seen\": 756, \"train_examples_seen\": 47817, \"impatience\": 3, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:04:56.214 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 74.6416\n",
            "2018-12-10 09:04:56.215 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 09:04:56.222 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.6416}, \"time_spent\": \"0:25:00\", \"epochs_done\": 28, \"batches_seen\": 784, \"train_examples_seen\": 49588, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:05:52.748 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.6416\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.2857}, \"time_spent\": \"0:25:56\", \"epochs_done\": 29, \"batches_seen\": 812, \"train_examples_seen\": 51359, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:06:47.435 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.6416\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 73.5746}, \"time_spent\": \"0:26:51\", \"epochs_done\": 30, \"batches_seen\": 840, \"train_examples_seen\": 53130, \"impatience\": 2, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:07:43.92 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.6416\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.2126}, \"time_spent\": \"0:27:47\", \"epochs_done\": 31, \"batches_seen\": 868, \"train_examples_seen\": 54901, \"impatience\": 3, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:08:38.453 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 74.6416\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.618}, \"time_spent\": \"0:28:42\", \"epochs_done\": 32, \"batches_seen\": 896, \"train_examples_seen\": 56672, \"impatience\": 4, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:09:34.330 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 74.8637\n",
            "2018-12-10 09:09:34.332 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 09:09:34.337 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.8637}, \"time_spent\": \"0:29:38\", \"epochs_done\": 33, \"batches_seen\": 924, \"train_examples_seen\": 58443, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:10:29.390 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 75.0371\n",
            "2018-12-10 09:10:29.391 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 09:10:29.393 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 75.0371}, \"time_spent\": \"0:30:33\", \"epochs_done\": 34, \"batches_seen\": 952, \"train_examples_seen\": 60214, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:11:24.875 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 75.0371\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.8642}, \"time_spent\": \"0:31:28\", \"epochs_done\": 35, \"batches_seen\": 980, \"train_examples_seen\": 61985, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:12:19.376 INFO in 'deeppavlov.core.commands.train'['train'] at line 571: New best ner_f1 of 75.0863\n",
            "2018-12-10 09:12:19.377 INFO in 'deeppavlov.core.commands.train'['train'] at line 573: Saving model\n",
            "2018-12-10 09:12:19.379 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [saving model to /content/models/onthology_objects/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 75.0863}, \"time_spent\": \"0:32:23\", \"epochs_done\": 36, \"batches_seen\": 1008, \"train_examples_seen\": 63756, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:13:15.665 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 75.0863\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.4439}, \"time_spent\": \"0:33:19\", \"epochs_done\": 37, \"batches_seen\": 1036, \"train_examples_seen\": 65527, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:14:12.19 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 75.0863\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.0668}, \"time_spent\": \"0:34:16\", \"epochs_done\": 38, \"batches_seen\": 1064, \"train_examples_seen\": 67298, \"impatience\": 2, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:15:06.871 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 75.0863\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 73.3927}, \"time_spent\": \"0:35:10\", \"epochs_done\": 39, \"batches_seen\": 1092, \"train_examples_seen\": 69069, \"impatience\": 3, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:16:01.386 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 75.0863\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 73.4714}, \"time_spent\": \"0:36:05\", \"epochs_done\": 40, \"batches_seen\": 1120, \"train_examples_seen\": 70840, \"impatience\": 4, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:16:55.275 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 75.0863\n",
            "2018-12-10 09:16:55.277 INFO in 'deeppavlov.models.ner.network'['network'] at line 343: Dropping learning rate from 1.0e-03 to 1.0e-04\n",
            "2018-12-10 09:16:55.287 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 43: [loading model from /content/models/onthology_objects/model_no_pos]\n",
            "2018-12-10 09:16:55.316 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from /content/models/onthology_objects/model_no_pos\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.7036}, \"time_spent\": \"0:36:59\", \"epochs_done\": 41, \"batches_seen\": 1148, \"train_examples_seen\": 72611, \"impatience\": 5, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:17:49.201 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 75.0863\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.7903}, \"time_spent\": \"0:37:53\", \"epochs_done\": 42, \"batches_seen\": 1176, \"train_examples_seen\": 74382, \"impatience\": 6, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:18:43.129 INFO in 'deeppavlov.core.commands.train'['train'] at line 578: Did not improve on the ner_f1 of 75.0863\n",
            "2018-12-10 09:18:43.130 INFO in 'deeppavlov.core.commands.train'['train'] at line 589: Ran out of patience\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 74.7535}, \"time_spent\": \"0:38:47\", \"epochs_done\": 43, \"batches_seen\": 1204, \"train_examples_seen\": 76153, \"impatience\": 7, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:18:43.441 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/word.dict]\n",
            "2018-12-10 09:18:43.457 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/tag.dict]\n",
            "2018-12-10 09:18:43.459 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/char.dict]\n",
            "2018-12-10 09:18:43.462 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/content/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2018-12-10 09:18:43.463 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 204: loading projection weights from /content/downloads/embeddings/glove.6B.100d.txt\n",
            "2018-12-10 09:18:43.465 DEBUG in 'smart_open.smart_open_lib'['smart_open_lib'] at line 176: {'kw': {}, 'mode': 'rb', 'uri': '/content/downloads/embeddings/glove.6B.100d.txt'}\n",
            "2018-12-10 09:19:16.977 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 266: loaded (400000, 100) matrix from /content/downloads/embeddings/glove.6B.100d.txt\n",
            "2018-12-10 09:19:18.669 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2018-12-10 09:19:18.782 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2018-12-10 09:19:20.800 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 43: [loading model from /content/models/onthology_objects/model_no_pos]\n",
            "2018-12-10 09:19:20.832 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from /content/models/onthology_objects/model_no_pos\n",
            "2018-12-10 09:19:20.924 INFO in 'deeppavlov.core.commands.train'['train'] at line 217: Testing the best saved model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 75.0863}, \"time_spent\": \"0:00:02\"}}\n",
            "{\"test\": {\"eval_examples_count\": 223, \"metrics\": {\"ner_f1\": 73.8269}, \"time_spent\": \"0:00:02\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:19:24.829 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/word.dict]\n",
            "2018-12-10 09:19:24.850 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/tag.dict]\n",
            "2018-12-10 09:19:24.853 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/char.dict]\n",
            "2018-12-10 09:19:24.857 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/content/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2018-12-10 09:19:24.859 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 204: loading projection weights from /content/downloads/embeddings/glove.6B.100d.txt\n",
            "2018-12-10 09:19:24.861 DEBUG in 'smart_open.smart_open_lib'['smart_open_lib'] at line 176: {'kw': {}, 'mode': 'rb', 'uri': '/content/downloads/embeddings/glove.6B.100d.txt'}\n",
            "2018-12-10 09:19:58.241 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 266: loaded (400000, 100) matrix from /content/downloads/embeddings/glove.6B.100d.txt\n",
            "2018-12-10 09:19:59.807 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2018-12-10 09:19:59.921 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2018-12-10 09:20:01.965 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 43: [loading model from /content/models/onthology_objects/model_no_pos]\n",
            "2018-12-10 09:20:01.998 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from /content/models/onthology_objects/model_no_pos\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "PHrN1C1UQz2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "ddb9a868-f2b8-477d-a6ad-c8809bbdd7fd"
      },
      "cell_type": "code",
      "source": [
        "!python -m deeppavlov evaluate config.json"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
            "2018-12-10 09:21:55.111 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/word.dict]\n",
            "2018-12-10 09:21:55.124 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/tag.dict]\n",
            "2018-12-10 09:21:55.126 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 100: [loading vocabulary from /content/models/onthology_objects/char.dict]\n",
            "Using TensorFlow backend.\n",
            "2018-12-10 09:21:56.700 DEBUG in 'gensim.models.doc2vec'['doc2vec'] at line 73: Fast version of gensim.models.doc2vec is being used\n",
            "2018-12-10 09:21:56.706 INFO in 'summa.preprocessing.cleaner'['textcleaner'] at line 20: 'pattern' package not found; tag filters are not available for English\n",
            "2018-12-10 09:21:56.712 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/content/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2018-12-10 09:21:56.712 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 204: loading projection weights from /content/downloads/embeddings/glove.6B.100d.txt\n",
            "2018-12-10 09:21:56.713 DEBUG in 'smart_open.smart_open_lib'['smart_open_lib'] at line 176: {'kw': {}, 'mode': 'rb', 'uri': '/content/downloads/embeddings/glove.6B.100d.txt'}\n",
            "2018-12-10 09:22:28.402 INFO in 'gensim.models.keyedvectors'['keyedvectors'] at line 266: loaded (400000, 100) matrix from /content/downloads/embeddings/glove.6B.100d.txt\n",
            "2018-12-10 09:22:35.826817: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2018-12-10 09:22:35.951 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2018-12-10 09:22:36.130 WARNING in 'tensorflow'['tf_logging'] at line 125: From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:862: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "seq_dim is deprecated, use seq_axis instead\n",
            "2018-12-10 09:22:36.131 WARNING in 'tensorflow'['tf_logging'] at line 125: From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "batch_dim is deprecated, use batch_axis instead\n",
            "2018-12-10 09:22:36.132 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 757: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "2018-12-10 09:22:38.32 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 43: [loading model from /content/models/onthology_objects/model_no_pos]\n",
            "2018-12-10 09:22:38.57 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from /content/models/onthology_objects/model_no_pos\n",
            "2018-12-10 09:22:38.112 INFO in 'deeppavlov.core.commands.train'['train'] at line 217: Testing the best saved model\n",
            "{\"valid\": {\"eval_examples_count\": 218, \"metrics\": {\"ner_f1\": 75.0863}, \"time_spent\": \"0:00:03\"}}\n",
            "{\"test\": {\"eval_examples_count\": 223, \"metrics\": {\"ner_f1\": 73.8269}, \"time_spent\": \"0:00:03\"}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "71zdO-IVbEgT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}