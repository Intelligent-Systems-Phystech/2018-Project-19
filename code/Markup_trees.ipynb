{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of trees.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "rdY16hLSRXXm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Теги и словарь"
      ]
    },
    {
      "metadata": {
        "id": "sS3rQJUL-V1o",
        "colab_type": "code",
        "outputId": "5a5b4da7-d65f-465b-eaf5-522f4c2d8ca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "Y8L_JWTOPBGT",
        "colab_type": "code",
        "outputId": "5d2c8b24-bd91-4a38-9367-1d28a3506d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pptree"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pptree in /usr/local/lib/python3.6/dist-packages (2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0j762TaI-WOK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pptree import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "etoBj7_syOqB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b6dC1erzh0XE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ILZ5MuU9U87A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6nm3vkx-Fgub",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Model"
      ]
    },
    {
      "metadata": {
        "id": "5G7yzSVRGTEK",
        "colab_type": "code",
        "outputId": "7e74306e-b4a5-447c-e78a-fe25f955bfe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m deeppavlov install ner_ontonotes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-10 09:16:51.373 INFO in 'deeppavlov.core.common.file'['file'] at line 31: Interpreting 'ner_ontonotes' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_ontonotes.json'\n",
            "Requirement already satisfied: gensim==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==2.3.0) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==2.3.0) (1.14.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim==2.3.0) (1.7.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==2.3.0) (1.9.62)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==2.3.0) (2.19.1)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==2.3.0) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==2.3.0) (0.98)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.62 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim==2.3.0) (1.12.62)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim==2.3.0) (0.1.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim==2.3.0) (0.9.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==2.3.0) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==2.3.0) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==2.3.0) (2.6)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim==2.3.0) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim==2.3.0) (0.14)\n",
            "Requirement already satisfied: tensorflow==1.10.0 in /usr/local/lib/python3.6/dist-packages (1.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (3.6.1)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (39.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.32.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.6.1)\n",
            "Requirement already satisfied: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.14.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.11.0)\n",
            "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (3.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GGSfymeFMxpv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "levels = [['entity']]\n",
        "levels.append(['physical entity', 'abstract entity'])\n",
        "levels.append(['physical object', 'physical process', 'psychological feature', 'attribute', 'measure'])\n",
        "levels.append(['geological formation', 'land', 'location', 'living thing', 'natural object', 'artifact'] +\n",
        "        ['economic process', 'human process', 'industrial process', 'natural process', 'organic process'] +\n",
        "        ['cognition', 'motivation', 'event', 'time', 'property', 'quality'] +\n",
        "        ['value', 'volume', 'time unit', 'time interval'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mjIXBrUvUE8w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "71-CzGL1M2XT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, synset, parent=None):\n",
        "        self.children = []\n",
        "        if parent:\n",
        "            parent.children.append(self)\n",
        "        self.parent = parent\n",
        "        self.synset = synset\n",
        "       \n",
        "    def __str__(self):\n",
        "        return ', '.join(self.synset.lemma_names() )#[0]\n",
        "    \n",
        "# листья вместо synset хранят в dict имена своего родителя, \n",
        "# имена всех его детей, детей их детей и тд\n",
        "class Leave:     \n",
        "    def __init__(self, tag_dict, parent):\n",
        "        self.children = []\n",
        "        parent.children = [self]\n",
        "        self.parent = parent\n",
        "        self.dict = tag_dict\n",
        "        \n",
        "    def __str__(self):\n",
        "        return '**leave: ' + str(len(self.dict))#', '.join(list(self.dict))\n",
        "    \n",
        "def hypo_closure(synset):\n",
        "    return synset.closure(hypo)\n",
        "\n",
        "def add_child(parent, synset):\n",
        "    child = Node(synset, parent)\n",
        "    return child\n",
        "\n",
        "def add_dict_child(parent):           \n",
        "    # заполняем dict\n",
        "    hypo_clsr = list(hypo_closure(parent.synset))\n",
        "    child_names = []\n",
        "    \n",
        "    for hyponym in hypo_clsr:\n",
        "        child_names += hyponym.lemma_names()\n",
        "        \n",
        "    # добавляем имена самого родителя: \n",
        "    # в dict лежат все слова, относящиеся к тегу-родителю\n",
        "    child_names += parent.synset.lemma_names()\n",
        "    tag_dict = set(child_names)\n",
        "    child = Leave(tag_dict, parent)\n",
        "        \n",
        "    return child"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U2zzKe_2M6KR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hypo = lambda s: s.hyponyms()\n",
        "hyper = lambda s: s.hypernyms()\n",
        "\n",
        "class Hierarchy:\n",
        "    \n",
        "    def __init__(self, levels, root_synset):\n",
        "        self.levels = levels\n",
        "        self.leaves = []\n",
        "        self.max_depth = len(levels) - 1\n",
        "        self.root_synset = root_synset\n",
        "        self.root = Node(root_synset)\n",
        "\n",
        "    def build(self, parent=None, depth=1) :\n",
        "        if not parent :\n",
        "            parent = self.root\n",
        "        \n",
        "        if depth > self.max_depth:\n",
        "            child = add_dict_child(parent)\n",
        "            self.leaves.append(child)\n",
        "            return\n",
        "\n",
        "        for synset in hypo(parent.synset):\n",
        "            #print (hypo(parent.synset))\n",
        "            if set(self.levels[depth]) & set([x.replace('_', ' ') for x in synset.lemma_names()]):\n",
        "                child = add_child(parent, synset)\n",
        "                self.build(child, depth+1)\n",
        "\n",
        "        return parent\n",
        "    \n",
        "    def get_tag(self, string):\n",
        "        string = string.replace(' ', '_')\n",
        "        candidates = []\n",
        "        for leave in self.leaves:\n",
        "            if string in leave.dict:\n",
        "                candidates.append(leave.parent.synset.lemma_names()[0])\n",
        "            \n",
        "        return random.choice(candidates) if candidates else 'O'\n",
        "      \n",
        "    def decrease_level(self):\n",
        "        new_leaves = []\n",
        "        new_tags = set()\n",
        "        for leave in self.leaves:\n",
        "            new_tags.add(leave.parent.parent)\n",
        "    \n",
        "        for new_tag in new_tags:\n",
        "            new_tag_dict = set()\n",
        "            for new_tag_child in new_tag.children:\n",
        "                new_tag_dict |= new_tag_child.children[0].dict # у тегов один потомок\n",
        "            \n",
        "            new_tag_dict |= set(new_tag.synset.lemma_names())          \n",
        "            new_leaves.append(Leave(new_tag_dict, new_tag))            \n",
        "            \n",
        "        self.max_depth -= 1\n",
        "        self.leaves = new_leaves\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CsRWy88YM9Gj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hierarchy = Hierarchy(levels, wn.synsets('entity')[0])\n",
        "entity = hierarchy.build()\n",
        "\n",
        "#whole = wn.synset('whole.n.02')\n",
        "#malually add artifact, living_thing, synset\n",
        "artifact = wn.synset('artifact.n.01')\n",
        "living_thing = wn.synset('living_thing.n.01')\n",
        "natural_object = wn.synset('natural_object.n.01')\n",
        "\n",
        "\n",
        "for i in entity.children :\n",
        "    if i.__str__() == 'physical_entity':\n",
        "        for j in i.children :\n",
        "            if j.__str__() == 'object, physical_object':\n",
        "                for synset in [artifact, living_thing, natural_object]:\n",
        "                    child = add_child(j, synset)\n",
        "                    hierarchy.leaves.append(add_dict_child(child))\n",
        "for i in entity.children :\n",
        "    if i.__str__() == 'abstraction, abstract_entity':\n",
        "        for j in i.children :\n",
        "            if j.__str__() == 'measure, quantity, amount':\n",
        "                    synset = wn.synset('time_period.n.01')\n",
        "                    child = add_child(j, synset)\n",
        "                    hierarchy.leaves.append(add_dict_child(child))\n",
        "                    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vy1L751vbK_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aohlqANjhsli",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#hierarchy.decrease_level()\n",
        "#print_tree(hierarchy.root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IsFyLBZUlCz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#hierarchy.decrease_level()\n",
        "#hierarchy.get_tag('pure mathematics')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "etlx5kT2yTYc",
        "colab_type": "code",
        "outputId": "2a9abb4a-0ece-497b-e122-45dfb5e6a80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Intelligent-Systems-Phystech/2018-Project-19/raw/master/X.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-10 09:17:01--  https://github.com/Intelligent-Systems-Phystech/2018-Project-19/raw/master/X.txt\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Intelligent-Systems-Phystech/2018-Project-19/master/X.txt [following]\n",
            "--2018-12-10 09:17:02--  https://raw.githubusercontent.com/Intelligent-Systems-Phystech/2018-Project-19/master/X.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7965488 (7.6M) [text/plain]\n",
            "Saving to: ‘X.txt.2’\n",
            "\n",
            "X.txt.2             100%[===================>]   7.60M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2018-12-10 09:17:02 (71.1 MB/s) - ‘X.txt.2’ saved [7965488/7965488]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9l5JTZerQXKa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "with open('X.txt') as f:\n",
        "    content = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGBnP86Ucm9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "len(content)\n",
        "texts = []\n",
        "for one_text in content:\n",
        "    texts.append(one_text.lower())\n",
        "text = texts[0]\n",
        "texts_array = []\n",
        "for text in texts:\n",
        "    texts_array.append(re.findall(r\"[\\w']+|[.,!?;\\'\\\"]\", text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lpRf5rjrcti9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tag_text(hierarchy, text):\n",
        "    string = ''\n",
        "    r = 0\n",
        "    for word_number in range(0,len(text)-1): # почему -1: последний символ всегда '.', а в проверке на словосочетание может выйти за массив\n",
        "        if r == 1: \n",
        "            r = 0\n",
        "            continue\n",
        "        if text[word_number]=='.':\n",
        "            string += '. O\\n\\n'\n",
        "        else:\n",
        "            if hierarchy.get_tag(text[word_number]+' '+text[word_number+1]) == 'O':\n",
        "                if hierarchy.get_tag(text[word_number]) == 'O':\n",
        "                    string += text[word_number] + ' O\\n'\n",
        "                else:\n",
        "                    string += text[word_number] + ' B-' + hierarchy.get_tag(text[word_number]) + '\\n'\n",
        "            else:\n",
        "                string += text[word_number] + ' B-' + hierarchy.get_tag(text[word_number]) + '\\n'\n",
        "                string += text[word_number+1] + ' I-' + hierarchy.get_tag(text[word_number]) + '\\n'\n",
        "                r = 1\n",
        "    string += '. O\\n\\n'\n",
        "    return string\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDp_XZVxdDJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "markup_third_lvl = []\n",
        "for text in texts_array[:5]: #для проверки пока размечаю первые 200 текстов. Потом можно убрать ограничение\n",
        "    markup_third_lvl.append(tag_text(hierarchy, text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C_maJT-6bPEA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print(markup_third_lvl[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VlFsxDc34FIc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "markup_second_lvl = []\n",
        "hierarchy.decrease_level()\n",
        "for text in texts_array[:5]:\n",
        "    markup_second_lvl.append(tag_text(hierarchy, text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SQJRBahU4G6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "markup_first_lvl = []\n",
        "hierarchy.decrease_level()\n",
        "for text in texts_array[:5]:\n",
        "    markup_first_lvl.append(tag_text(hierarchy, text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "68mmbhNTAwPC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def splitter(markup):\n",
        "    return markup[:3], markup[3:4], markup[4:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J3rkit-_AwCf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "markups = [markup_first_lvl, markup_second_lvl, markup_third_lvl]\n",
        "\n",
        "for i, markup in enumerate(markups):\n",
        "    train, test, validation = splitter(markup)\n",
        "    \n",
        "    import os\n",
        "\n",
        "    dest_dir = os.path.join(\"dataset_\" + str(i+1))\n",
        "    try:\n",
        "        os.makedirs(dest_dir)\n",
        "    except OSError:\n",
        "        pass # already exists\n",
        "    \n",
        "    with open(\"dataset_\" + str(i+1) +\"/train.txt\", \"w\") as file:\n",
        "        for j in train:\n",
        "            print(j, file=file)\n",
        "    with open(\"dataset_\" + str(i+1)+ \"/test.txt\", \"w\") as file:\n",
        "        for j in test:\n",
        "            print(j, file=file)\n",
        "    with open(\"dataset_\" + str(i+1) + \"/validation.txt\", \"w\") as file:\n",
        "        for j in validation:\n",
        "            print(j, file=file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VzFokT4hVpxX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CgmfOHxzY5rm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JmaQnNkJsBry",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}